---
name: batch-jd-processor
description: Batch job description processor using MANUAL REVIEW by parallel subagents. NO automated scripts allowed. Reads Excel/CSV with job data, splits into groups, launches max subagents for human-like analysis against user filter criteria. Outputs color-coded Excel with PASS/REJECT/ERROR classifications and detailed reasoning. Triggers include "æ‰¹é‡å¤„ç†è¿™äº›JD", "å¸®æˆ‘ç­›é€‰è¿™äº›èŒä½", "å¤„ç†Excelé‡Œçš„èŒä½", "batch filter jobs", "ç”¨batch jd process".
---

# Batch JD Processor

Process job batches through **parallel manual review** by subagents. Each subagent reads jobs like a human and applies user's filter criteria.

## Core Rules

### â›” Prohibitions
- NO automated scripts (no `filter_all_jobs.py`, no regex scripts)
- NO keyword extraction scripts

### âœ… Required Approach
- Split jobs into groups (5 per group)
- Launch ALL subagents in SINGLE message
- Each subagent manually reads every job (5 jobs per agent)
- Provide detailed reasoning for every decision

## Three-Tier Classification

**PASS** - Meets all criteria, recommend applying
**REJECT** - Fails filter criteria (location/experience/cert/position type)
**ERROR** - Cannot evaluate (missing JD, corrupted data, missing fields)

**Critical:** Use ERROR for data problems, REJECT for criteria failures.

Examples:
```json
{"filter_result": "ERROR", "reason": "JDå†…å®¹ç¼ºå¤±ï¼Œæ— æ³•è¯„ä¼°èŒä½è¦æ±‚"}
{"filter_result": "REJECT", "reason": "è¦æ±‚3å¹´ç»éªŒï¼Œç”¨æˆ·éœ€è¦0å¹´entry-level"}
{"filter_result": "PASS", "reason": "Entry-level Data Analystï¼ŒåŒ¹é…ç†æƒ³å²—ä½ï¼Œä½äºToronto"}
```

## Workflow

### Step 0: Display Filter Criteria
Read and display `user_filter.json` showing location, experience, certifications, ideal positions, avoid categories.

### Step 1: Load Data
Parse Excel/CSV into JSON for subagents:
```python
import pandas as pd, json

df = pd.read_csv('input.csv') if file.endswith('.csv') else pd.read_excel('input.xlsx')
jobs = [{
    'job_id': str(row.get('Job ID', f'job_{idx}')),
    'title': row.get('Title', ''),
    'location': row.get('Location', ''),
    'url': row.get('URL', ''),
    'full_jd': row.get('Job Description', ''),
    'posted_date': row.get('Posted Date', '')
} for idx, row in df.iterrows()]

with open('all_jobs.json', 'w', encoding='utf-8') as f:
    json.dump(jobs, f, indent=2, ensure_ascii=False)
```

### Step 2: Split into Groups
Calculate subagents: **num_agents = JDæ€»æ•° / 5** (æ¯ä¸ªagentå¤„ç†5ä¸ªJD)

```python
import math
num_agents = max(1, math.ceil(len(jobs) / 5))  # æ¯5ä¸ªJDåˆ†é…1ä¸ªagent
jobs_per_agent = math.ceil(len(jobs) / num_agents)

for i in range(num_agents):
    group = jobs[i*jobs_per_agent : (i+1)*jobs_per_agent]
    with open(f'jobs_group_{i+1}.json', 'w', encoding='utf-8') as f:
        json.dump(group, f, indent=2, ensure_ascii=False)
```

### Step 3: Launch Subagents (In SINGLE Message)

**Prompt template for each subagent:**
```
Review Group {N}: /path/to/jobs_group_{N}.json
Filter: /path/to/user_filter.json

For EACH job:
1. Check data quality first - Missing JD/fields? â†’ ERROR
2. Read title and full JD carefully
3. Check ALL criteria: location, experience, certs, position type, avoid categories
4. Classify as PASS/REJECT/ERROR with specific reason

Output JSON: [{job_id, title, url, location, filter_result, reason}]
Save to: /path/to/group_{N}_results.json

Rules:
- NO scripts, manual reading only
- ERROR for data issues, REJECT for criteria failures
- Specific reasons (e.g. "è¦æ±‚2å¹´ç»éªŒ" not "ä¸ç¬¦åˆ")
```

### Step 4: Merge & Generate Excel

```python
import json, pandas as pd
from openpyxl import load_workbook
from openpyxl.styles import PatternFill, Font, Alignment

# Merge results
all_results = []
for i in range(1, num_agents + 1):
    with open(f'group_{i}_results.json', 'r', encoding='utf-8') as f:
        all_results.extend(json.load(f))

# Statistics
pass_count = sum(1 for r in all_results if r['filter_result'] == 'PASS')
reject_count = sum(1 for r in all_results if r['filter_result'] == 'REJECT')
error_count = sum(1 for r in all_results if r['filter_result'] == 'ERROR')

# Create Excel
df = pd.DataFrame(all_results)
df['sort_key'] = df['filter_result'].map({'PASS': 0, 'REJECT': 1, 'ERROR': 2})
df = df.sort_values('sort_key').drop('sort_key', axis=1)
df.to_excel('output.xlsx', index=False)

# Color code
wb = load_workbook('output.xlsx')
ws = wb.active
green = PatternFill(start_color='C6EFCE', end_color='C6EFCE', fill_type='solid')
red = PatternFill(start_color='FFC7CE', end_color='FFC7CE', fill_type='solid')
yellow = PatternFill(start_color='FFEB9C', end_color='FFEB9C', fill_type='solid')

for row in ws.iter_rows(min_row=2):
    result = row[4].value
    row[4].fill = green if result == 'PASS' else red if result == 'REJECT' else yellow

wb.save('output.xlsx')
```

### Step 5: Present Results

```
ğŸ“Š æ‰¹é‡ç­›é€‰å®Œæˆï¼
æ€»èŒä½: {total} | âœ… PASS: {pass} | âŒ REJECT: {reject} | âš ï¸ ERROR: {error}

ğŸ¯ æ¨èç”³è¯·èŒä½ï¼ˆTop 5ï¼‰:
[List PASS jobs with title, location, reason, URL]

ğŸ“‹ æ‹’ç»åŸå› ç»Ÿè®¡:
[Group REJECT by reason with counts]

âš ï¸ é”™è¯¯ç»Ÿè®¡:
[Group ERROR by reason with counts]

[Excel download link]
```

## Subagent Quality Checklist

âœ… Read data quality first (missing JD â†’ ERROR, not REJECT)
âœ… Read full job description, don't skim
âœ… Check ALL criteria (location, experience, certs, position type, avoid)
âœ… Specific reasoning ("è¦æ±‚3å¹´ç»éªŒ" not "ä¸ç¬¦åˆè¦æ±‚")
âœ… Handle edge cases (bilingual, "Associate" titles, "preferred" vs "required")

## Common Mistakes

âŒ Using scripts instead of manual review
âŒ Launching subagents sequentially (launch ALL in one message)
âŒ Vague reasoning
âŒ ERROR for criteria failures (use ERROR only for data issues)

## Performance

| Batch Size | Agents | Jobs/Agent | Estimated Time |
|------------|--------|------------|----------------|
| 25         | 5      | 5          | 2-3min |
| 50         | 10     | 5          | 3-5min |
| 100        | 20     | 5          | 5-8min |
| 200        | 40     | 5          | 10-15min |

Manual review is slower than scripts but catches nuances and context-dependent requirements. Each agent processes exactly 5 JDs for consistent workload distribution.
